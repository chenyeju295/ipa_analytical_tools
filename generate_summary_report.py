#!/usr/bin/env python3
"""
IPAåˆ†ææ€»ç»“æŠ¥å‘Šç”Ÿæˆå™¨
"""

import os
import json
import sqlite3
from datetime import datetime

def generate_summary_report():
    """ç”Ÿæˆç»¼åˆæ€»ç»“æŠ¥å‘Š"""
    
    print("ğŸ” ç”ŸæˆIPAåˆ†ææ€»ç»“æŠ¥å‘Š...")
    
    # åŠ è½½ç›¸ä¼¼æ€§åˆ†æç»“æœ
    similarity_file = 'analysis_reports/similarity_analysis.json'
    if os.path.exists(similarity_file):
        with open(similarity_file, 'r', encoding='utf-8') as f:
            similarity_data = json.load(f)
    else:
        similarity_data = {}
    
    # è¿æ¥è¯åº“æ•°æ®åº“
    db_path = 'word_library.db'
    if os.path.exists(db_path):
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # è·å–åº”ç”¨ç»Ÿè®¡
        cursor.execute("SELECT COUNT(*) FROM apps")
        total_apps = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(*) FROM words")
        total_words = cursor.fetchone()[0]
        
        # è·å–åˆ†ç±»ç»Ÿè®¡
        cursor.execute("""
            SELECT category, COUNT(*) as count 
            FROM words 
            GROUP BY category 
            ORDER BY count DESC
        """)
        category_stats = cursor.fetchall()
        
        # è·å–å…±åŒå•è¯ç»Ÿè®¡
        cursor.execute("""
            SELECT frequency, COUNT(*) as word_count
            FROM (
                SELECT word_id, COUNT(*) as frequency
                FROM word_app_relations
                GROUP BY word_id
            ) AS freq_stats
            GROUP BY frequency
            ORDER BY frequency DESC
        """)
        frequency_stats = cursor.fetchall()
        
        # è·å–åº”ç”¨ä¿¡æ¯
        cursor.execute("""
            SELECT a.app_name, COUNT(war.word_id) as word_count
            FROM apps a
            LEFT JOIN word_app_relations war ON a.id = war.app_id
            GROUP BY a.id, a.app_name
            ORDER BY word_count DESC
        """)
        app_stats = cursor.fetchall()
        
        conn.close()
    else:
        total_apps = 0
        total_words = 0
        category_stats = []
        frequency_stats = []
        app_stats = []
    
    # ç”ŸæˆæŠ¥å‘Š
    report = []
    report.append("# IPAåˆ†æå·¥å…· - ç»¼åˆæ€»ç»“æŠ¥å‘Š")
    report.append(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    
    # åŸºæœ¬ç»Ÿè®¡
    report.append("## ğŸ“Š åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯")
    report.append(f"- **åˆ†æåº”ç”¨æ€»æ•°**: {total_apps}")
    report.append(f"- **è¯åº“æ€»è¯æ±‡æ•°**: {total_words:,}")
    
    if app_stats:
        report.append(f"- **æœ€å¤§åº”ç”¨è¯æ±‡æ•°**: {max(count for _, count in app_stats):,}")
        report.append(f"- **æœ€å°åº”ç”¨è¯æ±‡æ•°**: {min(count for _, count in app_stats):,}")
        avg_words = sum(count for _, count in app_stats) / len(app_stats)
        report.append(f"- **å¹³å‡è¯æ±‡æ•°**: {avg_words:,.0f}\n")
    
    # åº”ç”¨åˆ†æ
    if app_stats:
        report.append("## ğŸ“± åº”ç”¨è¯æ±‡ç»Ÿè®¡")
        report.append("| åº”ç”¨åç§° | è¯æ±‡æ•°é‡ | å æ¯” |")
        report.append("|----------|----------|------|")
        for app_name, word_count in app_stats:
            percentage = (word_count / total_words * 100) if total_words > 0 else 0
            report.append(f"| {app_name} | {word_count:,} | {percentage:.1f}% |")
        report.append("")
    
    # åˆ†ç±»ç»Ÿè®¡
    if category_stats:
        report.append("## ğŸ·ï¸ è¯æ±‡åˆ†ç±»ç»Ÿè®¡")
        report.append("| åˆ†ç±» | æ•°é‡ | å æ¯” |")
        report.append("|------|------|------|")
        for category, count in category_stats:
            percentage = (count / total_words * 100) if total_words > 0 else 0
            report.append(f"| {category} | {count:,} | {percentage:.1f}% |")
        report.append("")
    
    # å…±åŒè¯æ±‡ç»Ÿè®¡
    if frequency_stats:
        report.append("## ğŸ”„ è¯æ±‡å…±äº«åˆ†æ")
        report.append("| å‡ºç°åº”ç”¨æ•° | è¯æ±‡æ•°é‡ | ç™¾åˆ†æ¯” |")
        report.append("|------------|----------|--------|")
        total_unique_words = sum(count for _, count in frequency_stats)
        for frequency, word_count in frequency_stats:
            percentage = (word_count / total_unique_words * 100) if total_unique_words > 0 else 0
            report.append(f"| {frequency} | {word_count:,} | {percentage:.1f}% |")
        report.append("")
    
    # Bundle IDåˆ†æ
    report.append("## ğŸ·ï¸ Bundle IDåˆ†æ")
    
    # è¯»å–åº”ç”¨åˆ†ææ–‡ä»¶è·å–Bundle IDä¿¡æ¯
    bundle_ids = []
    analysis_dir = 'analysis_reports'
    for filename in os.listdir(analysis_dir):
        if filename.endswith('_analysis.json') and filename != 'similarity_analysis.json':
            filepath = os.path.join(analysis_dir, filename)
            try:
                with open(filepath, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    bundle_id = data.get('app_info', {}).get('bundle_id', 'N/A')
                    app_name = filename.replace('_analysis.json', '')
                    bundle_ids.append((app_name, bundle_id))
            except Exception:
                continue
    
    if bundle_ids:
        report.append("| åº”ç”¨åç§° | Bundle ID |")
        report.append("|----------|-----------|")
        for app_name, bundle_id in bundle_ids:
            report.append(f"| {app_name} | {bundle_id} |")
        
        # åˆ†æå…±åŒå‰ç¼€
        valid_bundle_ids = [bid for _, bid in bundle_ids if bid != 'N/A']
        if valid_bundle_ids:
            common_prefix = os.path.commonprefix(valid_bundle_ids)
            report.append(f"\n**å…¬å…±å‰ç¼€**: `{common_prefix}` (é•¿åº¦: {len(common_prefix)} å­—ç¬¦)")
        report.append("")
    
    # å…³é”®å‘ç°
    report.append("## ğŸ¯ å…³é”®å‘ç°")
    findings = []
    
    if frequency_stats:
        # ç»Ÿè®¡å®Œå…¨å…±åŒçš„è¯æ±‡
        for frequency, word_count in frequency_stats:
            if frequency == total_apps and total_apps > 1:
                findings.append(f"- æ‰€æœ‰ {total_apps} ä¸ªåº”ç”¨éƒ½åŒ…å« {word_count:,} ä¸ªå…±åŒè¯æ±‡")
                break
    
    if category_stats:
        top_category = category_stats[0]
        findings.append(f"- æœ€å¤§è¯æ±‡åˆ†ç±»æ˜¯ '{top_category[0]}'ï¼ŒåŒ…å« {top_category[1]:,} ä¸ªè¯æ±‡")
    
    if bundle_ids and len(bundle_ids) > 1:
        prefixes = set()
        for _, bundle_id in bundle_ids:
            if bundle_id != 'N/A' and '.' in bundle_id:
                prefixes.add(bundle_id.split('.')[0])
        if len(prefixes) == 1:
            findings.append(f"- æ‰€æœ‰åº”ç”¨ä½¿ç”¨ç›¸åŒçš„Bundle IDå‰ç¼€ï¼Œå¯èƒ½æ¥è‡ªåŒä¸€å¼€å‘è€…")
    
    if not findings:
        findings.append("- åº”ç”¨å…·æœ‰è¾ƒå¼ºçš„ç‹¬ç«‹æ€§ï¼Œå„è‡ªç‰¹å¾æ˜æ˜¾")
    
    for finding in findings:
        report.append(finding)
    
    report.append("")
    
    # å»ºè®®
    report.append("## ğŸ’¡ åˆ†æå»ºè®®")
    suggestions = [
        "- å…³æ³¨é«˜é¢‘å…±åŒè¯æ±‡ï¼Œè¿™äº›å¯èƒ½ä»£è¡¨å¸¸ç”¨çš„æ¡†æ¶æˆ–åº“",
        "- Bundle IDæ¨¡å¼å¯ä»¥å¸®åŠ©è¯†åˆ«åº”ç”¨çš„å¼€å‘æ¥æºå’Œç»„ç»‡å…³ç³»",
        "- è¯æ±‡åˆ†ç±»ç»Ÿè®¡æœ‰åŠ©äºäº†è§£åº”ç”¨çš„åŠŸèƒ½é‡ç‚¹å’ŒæŠ€æœ¯ç‰¹å¾"
    ]
    
    for suggestion in suggestions:
        report.append(suggestion)
    
    # ä¿å­˜æŠ¥å‘Š
    report_content = '\n'.join(report)
    
    # ä¿å­˜ä¸ºMarkdownæ–‡ä»¶
    with open('analysis_reports/ç»¼åˆåˆ†ææŠ¥å‘Š.md', 'w', encoding='utf-8') as f:
        f.write(report_content)
    
    # æ‰“å°æŠ¥å‘Š
    print(report_content)
    
    print(f"\nâœ… ç»¼åˆåˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: analysis_reports/ç»¼åˆåˆ†ææŠ¥å‘Š.md")

if __name__ == '__main__':
    generate_summary_report() 