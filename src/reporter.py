"""
æŠ¥å‘Šç”Ÿæˆå™¨
è´Ÿè´£ç”Ÿæˆåˆ†ææŠ¥å‘Šï¼Œæ”¯æŒJSONå’ŒCSVæ ¼å¼è¾“å‡º
"""

import json
import csv
from datetime import datetime
from pathlib import Path
from typing import Dict, List


class Reporter:
    """æŠ¥å‘Šç”Ÿæˆå™¨"""
    
    def __init__(self, analysis_data: Dict):
        """åˆå§‹åŒ–æŠ¥å‘Šç”Ÿæˆå™¨
        
        Args:
            analysis_data: åˆ†æç»“æœæ•°æ®
        """
        self.data = analysis_data
        self.timestamp = datetime.now().isoformat()
    
    def print_summary(self):
        """æ‰“å°å‘½ä»¤è¡Œæ‘˜è¦"""
        print("\n" + "=" * 60)
        print("IPA åˆ†ææŠ¥å‘Šæ‘˜è¦")
        print("=" * 60)
        
        # åº”ç”¨åŸºæœ¬ä¿¡æ¯
        app_info = self.data.get('app_info', {})
        print(f"\nğŸ“± åº”ç”¨ä¿¡æ¯:")
        print(f"   åº”ç”¨åç§°: {app_info.get('name', 'æœªçŸ¥')}")
        print(f"   Bundle ID: {app_info.get('bundle_id', 'æœªçŸ¥')}")
        print(f"   ç‰ˆæœ¬: {app_info.get('version', 'æœªçŸ¥')}")
        print(f"   æ„å»ºç‰ˆæœ¬: {app_info.get('build_version', 'æœªçŸ¥')}")
        print(f"   å¹³å°: {app_info.get('platform', 'æœªçŸ¥')}")
        print(f"   æœ€ä½ç³»ç»Ÿç‰ˆæœ¬: {app_info.get('minimum_os_version', 'æœªçŸ¥')}")
        
        # æ–‡ä»¶å¤§å°ä¿¡æ¯
        file_size = app_info.get('file_size', 0)
        app_size = app_info.get('app_size', 0)
        print(f"\nğŸ“¦ å¤§å°ä¿¡æ¯:")
        print(f"   IPAæ–‡ä»¶å¤§å°: {self._format_size(file_size)}")
        print(f"   åº”ç”¨åŒ…å¤§å°: {self._format_size(app_size)}")
        
        # å­—ç¬¦ä¸²åˆ†æ
        strings_data = self.data.get('strings', {})
        print(f"\nğŸ”¤ å­—ç¬¦ä¸²åˆ†æ:")
        print(f"   æ€»å­—ç¬¦ä¸²æ•°: {strings_data.get('total_strings', 0):,}")
        print(f"   å”¯ä¸€å­—ç¬¦ä¸²æ•°: {strings_data.get('unique_strings', 0):,}")
        
        # è®¡ç®—é‡å¤ç‡
        total_strings = strings_data.get('total_strings', 0)
        unique_strings = strings_data.get('unique_strings', 0)
        if total_strings > 0:
            duplicate_rate = (total_strings - unique_strings) / total_strings * 100
            print(f"   é‡å¤ç‡: {duplicate_rate:.1f}%")
        
        # å­—ç¬¦ä¸²åˆ†ç±»ç»Ÿè®¡
        categories = strings_data.get('categories', {})
        if categories:
            print(f"\n   å­—ç¬¦ä¸²åˆ†ç±»:")
            for category, strings_list in categories.items():
                if strings_list and len(strings_list) > 0:
                    print(f"     {category}: {len(strings_list)} ä¸ª")
        
        # é‡å¤å­—ç¬¦ä¸²
        duplicates = strings_data.get('duplicates', {})
        duplicate_count = duplicates.get('count', 0)
        if duplicate_count > 0:
            print(f"   é‡å¤å­—ç¬¦ä¸²: {duplicate_count} ä¸ª")
        
        # èµ„æºåˆ†æ
        resources_data = self.data.get('resources', {})
        print(f"\nğŸ“ èµ„æºåˆ†æ:")
        print(f"   æ€»æ–‡ä»¶æ•°: {resources_data.get('total_files', 0):,}")
        print(f"   æ€»èµ„æºå¤§å°: {self._format_size(resources_data.get('total_size', 0))}")
        
        # èµ„æºåˆ†ç±»ç»Ÿè®¡
        resource_categories = resources_data.get('categories', {})
        if resource_categories:
            print(f"\n   èµ„æºåˆ†ç±»:")
            for category, file_list in resource_categories.items():
                if file_list and len(file_list) > 0:
                    total_size = sum(f.get('size', 0) for f in file_list)
                    print(f"     {category}: {len(file_list)} ä¸ªæ–‡ä»¶ ({self._format_size(total_size)})")
        
        # ç‰¹æ®Šæ–‡ä»¶
        special_files = resources_data.get('special_files', {})
        if special_files:
            print(f"\n   ç‰¹æ®Šæ–‡ä»¶:")
            for file_type, file_list in special_files.items():
                if file_list:
                    print(f"     {file_type}: {len(file_list)} ä¸ª")
        
        # å¤§æ–‡ä»¶
        large_files = resources_data.get('large_files', [])
        if large_files:
            print(f"\n   å¤§æ–‡ä»¶ (>1MB):")
            for file_info in large_files[:5]:  # æ˜¾ç¤ºå‰5ä¸ª
                print(f"     {file_info['name']}: {self._format_size(file_info['size'])}")
        
        print("\n" + "=" * 60)
    
    def generate_json(self, output_path: str):
        """ç”ŸæˆJSONæ ¼å¼æŠ¥å‘Š
        
        Args:
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        report_data = self._prepare_report_data()
        
        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(report_data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            raise Exception(f"ç”ŸæˆJSONæŠ¥å‘Šå¤±è´¥: {e}")
    
    def generate_csv(self, output_path: str):
        """ç”ŸæˆCSVæ ¼å¼æŠ¥å‘Š
        
        Args:
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        try:
            # åˆ›å»ºè¾“å‡ºç›®å½•
            output_path = Path(output_path)
            output_dir = output_path.parent
            output_dir.mkdir(parents=True, exist_ok=True)
            
            # ç”Ÿæˆå¤šä¸ªCSVæ–‡ä»¶
            base_name = output_path.stem
            
            # 1. åº”ç”¨åŸºæœ¬ä¿¡æ¯
            self._generate_app_info_csv(output_dir / f"{base_name}_app_info.csv")
            
            # 2. å­—ç¬¦ä¸²ç»Ÿè®¡
            self._generate_strings_csv(output_dir / f"{base_name}_strings.csv")
            
            # 3. èµ„æºç»Ÿè®¡
            self._generate_resources_csv(output_dir / f"{base_name}_resources.csv")
            
            # 4. é‡å¤æ–‡ä»¶
            self._generate_duplicates_csv(output_dir / f"{base_name}_duplicates.csv")
            
        except Exception as e:
            raise Exception(f"ç”ŸæˆCSVæŠ¥å‘Šå¤±è´¥: {e}")
    
    def _prepare_report_data(self) -> Dict:
        """å‡†å¤‡æŠ¥å‘Šæ•°æ®"""
        report_data = {
            'report_info': {
                'generated_at': self.timestamp,
                'tool_version': self.data.get('analysis_meta', {}).get('tool_version', '1.0.0'),
                'source_file': self.data.get('analysis_meta', {}).get('source_file', '')
            },
            'app_info': self.data.get('app_info', {}),
            'strings_analysis': self.data.get('strings', {}),
            'resources_analysis': self.data.get('resources', {}),
            'summary': self._generate_summary()
        }
        
        return report_data
    
    def _generate_summary(self) -> Dict:
        """ç”Ÿæˆæ‘˜è¦ä¿¡æ¯"""
        app_info = self.data.get('app_info', {})
        strings_data = self.data.get('strings', {})
        resources_data = self.data.get('resources', {})
        
        summary = {
            'app_name': app_info.get('name', 'æœªçŸ¥'),
            'file_size_mb': round(app_info.get('file_size', 0) / 1024 / 1024, 2),
            'total_strings': strings_data.get('total_strings', 0),
            'unique_strings': strings_data.get('unique_strings', 0),
            'duplicate_rate': 0,
            'total_files': resources_data.get('total_files', 0),
            'total_resource_size_mb': round(resources_data.get('total_size', 0) / 1024 / 1024, 2)
        }
        
        # è®¡ç®—é‡å¤ç‡
        if summary['total_strings'] > 0:
            summary['duplicate_rate'] = round(
                (summary['total_strings'] - summary['unique_strings']) / summary['total_strings'] * 100, 2
            )
        
        return summary
    
    def _generate_app_info_csv(self, output_path: Path):
        """ç”Ÿæˆåº”ç”¨ä¿¡æ¯CSV"""
        app_info = self.data.get('app_info', {})
        
        with open(output_path, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow(['å±æ€§', 'å€¼'])
            
            for key, value in app_info.items():
                if key != 'plist_data':  # æ’é™¤å®Œæ•´çš„plistæ•°æ®
                    if key.endswith('_size'):
                        value = self._format_size(value)
                    writer.writerow([key, str(value)])
    
    def _generate_strings_csv(self, output_path: Path):
        """ç”Ÿæˆå­—ç¬¦ä¸²ç»Ÿè®¡CSV"""
        strings_data = self.data.get('strings', {})
        
        with open(output_path, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow(['ç±»åˆ«', 'æ•°é‡', 'ç¤ºä¾‹å­—ç¬¦ä¸²'])
            
            categories = strings_data.get('categories', {})
            for category, strings_list in categories.items():
                if strings_list:
                    # å–å‰3ä¸ªä½œä¸ºç¤ºä¾‹
                    examples = ', '.join(strings_list[:3])
                    if len(strings_list) > 3:
                        examples += f' ... (å…±{len(strings_list)}ä¸ª)'
                    writer.writerow([category, len(strings_list), examples])
    
    def _generate_resources_csv(self, output_path: Path):
        """ç”Ÿæˆèµ„æºç»Ÿè®¡CSV"""
        resources_data = self.data.get('resources', {})
        
        with open(output_path, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow(['æ–‡ä»¶å', 'è·¯å¾„', 'å¤§å°', 'ç±»å‹', 'æ‰©å±•å'])
            
            categories = resources_data.get('categories', {})
            for category, file_list in categories.items():
                for file_info in file_list:
                    writer.writerow([
                        file_info.get('name', ''),
                        file_info.get('path', ''),
                        self._format_size(file_info.get('size', 0)),
                        category,
                        file_info.get('extension', '')
                    ])
    
    def _generate_duplicates_csv(self, output_path: Path):
        """ç”Ÿæˆé‡å¤æ–‡ä»¶CSV"""
        strings_data = self.data.get('strings', {})
        resources_data = self.data.get('resources', {})
        
        with open(output_path, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow(['ç±»å‹', 'å†…å®¹', 'å‡ºç°æ¬¡æ•°', 'è¯´æ˜'])
            
            # é‡å¤å­—ç¬¦ä¸²
            duplicates = strings_data.get('duplicates', {})
            duplicate_strings = duplicates.get('strings', {})
            for string, count in duplicate_strings.items():
                writer.writerow(['å­—ç¬¦ä¸²', string, count, 'é‡å¤å­—ç¬¦ä¸²'])
            
            # é‡å¤æ–‡ä»¶ï¼ˆæŒ‰åç§°ï¼‰
            resource_duplicates = resources_data.get('duplicates', {})
            name_duplicates = resource_duplicates.get('by_name', {})
            for name, file_list in name_duplicates.items():
                paths = [f['path'] for f in file_list]
                writer.writerow(['æ–‡ä»¶å', name, len(file_list), f"è·¯å¾„: {'; '.join(paths)}"])
    
    def _format_size(self, size_bytes: int) -> str:
        """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°
        
        Args:
            size_bytes: å­—èŠ‚æ•°
            
        Returns:
            æ ¼å¼åŒ–çš„å¤§å°å­—ç¬¦ä¸²
        """
        if size_bytes == 0:
            return "0 B"
        
        units = ['B', 'KB', 'MB', 'GB', 'TB']
        unit_index = 0
        size = float(size_bytes)
        
        while size >= 1024 and unit_index < len(units) - 1:
            size /= 1024
            unit_index += 1
        
        if unit_index == 0:
            return f"{int(size)} {units[unit_index]}"
        else:
            return f"{size:.1f} {units[unit_index]}" 