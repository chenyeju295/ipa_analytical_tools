#!/usr/bin/env python3
"""
ç›¸ä¼¼æ€§åˆ†æè°ƒè¯•å·¥å…·
æ·±å…¥åˆ†æå­—ç¬¦ä¸²é‡å¤æƒ…å†µ
"""

import json
import sys
import os
from pathlib import Path
from collections import Counter, defaultdict

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from similarity_analyzer import SimilarityAnalyzer


def load_app_data(file_path):
    """åŠ è½½åº”ç”¨åˆ†ææ•°æ®"""
    with open(file_path, 'r', encoding='utf-8') as f:
        return json.load(f)


def extract_all_strings_detailed(data):
    """è¯¦ç»†æå–æ‰€æœ‰å­—ç¬¦ä¸²ï¼ŒåŒ…å«æ¥æºä¿¡æ¯"""
    strings_with_source = []
    
    strings_data = data.get('strings', {})
    categories = strings_data.get('categories', {})
    
    for category, string_list in categories.items():
        if isinstance(string_list, list):
            for item in string_list:
                if isinstance(item, str):
                    strings_with_source.append({
                        'content': item,
                        'category': category,
                        'type': 'string'
                    })
                elif isinstance(item, dict) and 'content' in item:
                    strings_with_source.append({
                        'content': item['content'],
                        'category': category,
                        'type': 'dict'
                    })
    
    return strings_with_source


def analyze_specific_apps(app_files):
    """åˆ†ææŒ‡å®šçš„åº”ç”¨æ–‡ä»¶"""
    apps_data = {}
    
    # åŠ è½½åº”ç”¨æ•°æ®
    for app_file in app_files:
        if not os.path.exists(app_file):
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {app_file}")
            continue
        
        data = load_app_data(app_file)
        app_name = data.get('app_info', {}).get('name', os.path.basename(app_file).replace('_analysis.json', ''))
        apps_data[app_name] = data
        print(f"âœ… åŠ è½½åº”ç”¨: {app_name}")
    
    if len(apps_data) < 2:
        print("âŒ éœ€è¦è‡³å°‘2ä¸ªåº”ç”¨æ–‡ä»¶è¿›è¡Œæ¯”è¾ƒ")
        return
    
    print(f"\nğŸ“Š å¼€å§‹åˆ†æ {len(apps_data)} ä¸ªåº”ç”¨...")
    
    # è¯¦ç»†æå–å­—ç¬¦ä¸²
    apps_strings_detailed = {}
    for app_name, data in apps_data.items():
        strings_detailed = extract_all_strings_detailed(data)
        apps_strings_detailed[app_name] = strings_detailed
        print(f"   {app_name}: {len(strings_detailed)} ä¸ªå­—ç¬¦ä¸²")
    
    # åˆ†æé‡å¤å­—ç¬¦ä¸²
    print(f"\nğŸ” åˆ†æå­—ç¬¦ä¸²é‡å¤æƒ…å†µ...")
    
    # æ”¶é›†æ‰€æœ‰å­—ç¬¦ä¸²
    all_strings = {}
    string_to_apps = defaultdict(list)
    
    for app_name, strings_list in apps_strings_detailed.items():
        app_strings = set()
        for string_info in strings_list:
            content = string_info['content']
            app_strings.add(content)
            string_to_apps[content].append({
                'app': app_name,
                'category': string_info['category']
            })
        all_strings[app_name] = app_strings
    
    # æ‰¾å‡ºé‡å¤å­—ç¬¦ä¸²
    duplicate_strings = {}
    for string_content, apps_info in string_to_apps.items():
        if len(apps_info) > 1:
            duplicate_strings[string_content] = apps_info
    
    print(f"æ€»è®¡é‡å¤å­—ç¬¦ä¸²: {len(duplicate_strings)}")
    
    # æŒ‰é‡å¤æ¬¡æ•°åˆ†ç»„
    duplicates_by_count = defaultdict(list)
    for string_content, apps_info in duplicate_strings.items():
        count = len(apps_info)
        duplicates_by_count[count].append({
            'content': string_content,
            'apps': [info['app'] for info in apps_info],
            'categories': [info['category'] for info in apps_info]
        })
    
    # æ˜¾ç¤ºç»Ÿè®¡
    print(f"\nğŸ“ˆ é‡å¤å­—ç¬¦ä¸²ç»Ÿè®¡:")
    for count in sorted(duplicates_by_count.keys(), reverse=True):
        strings_list = duplicates_by_count[count]
        print(f"   å‡ºç°åœ¨ {count} ä¸ªåº”ç”¨ä¸­: {len(strings_list)} ä¸ªå­—ç¬¦ä¸²")
    
    # æ˜¾ç¤ºå‰20ä¸ªæœ€é‡å¤çš„å­—ç¬¦ä¸²
    print(f"\nğŸ”„ å‰20ä¸ªæœ€é‡å¤çš„å­—ç¬¦ä¸²:")
    all_duplicates = []
    for count, strings_list in duplicates_by_count.items():
        for string_info in strings_list:
            all_duplicates.append((count, string_info))
    
    # æŒ‰é‡å¤æ¬¡æ•°å’Œå­—ç¬¦ä¸²é•¿åº¦æ’åº
    all_duplicates.sort(key=lambda x: (x[0], len(x[1]['content'])), reverse=True)
    
    for i, (count, string_info) in enumerate(all_duplicates[:20], 1):
        content = string_info['content']
        if len(content) > 60:
            content = content[:57] + "..."
        apps_str = ', '.join(string_info['apps'])
        categories_str = ', '.join(set(string_info['categories']))
        print(f"   {i:2}. [{count}æ¬¡] {content}")
        print(f"       åº”ç”¨: {apps_str}")
        print(f"       ç±»åˆ«: {categories_str}")
        print()
    
    # è®¡ç®—æ€»ä½“ç»Ÿè®¡
    total_strings = sum(len(strings) for strings in all_strings.values())
    unique_strings = len(set().union(*all_strings.values()))
    duplicate_count = sum(len(apps_info) - 1 for apps_info in duplicate_strings.values())
    
    print(f"ğŸ“Š æ€»ä½“ç»Ÿè®¡:")
    print(f"   æ€»å­—ç¬¦ä¸²æ•°: {total_strings}")
    print(f"   å”¯ä¸€å­—ç¬¦ä¸²æ•°: {unique_strings}")
    print(f"   é‡å¤å­—ç¬¦ä¸²æ•°: {duplicate_count}")
    print(f"   é‡å¤ç‡: {duplicate_count / total_strings * 100:.1f}%")
    
    # åˆ†æä¸åŒç±»åˆ«çš„é‡å¤æƒ…å†µ
    print(f"\nğŸ“‚ æŒ‰ç±»åˆ«åˆ†æé‡å¤æƒ…å†µ:")
    category_duplicates = defaultdict(int)
    for string_content, apps_info in duplicate_strings.items():
        for info in apps_info:
            category_duplicates[info['category']] += 1
    
    for category, count in sorted(category_duplicates.items(), key=lambda x: x[1], reverse=True):
        print(f"   {category}: {count} ä¸ªé‡å¤å­—ç¬¦ä¸²")


def main():
    if len(sys.argv) < 3:
        print("ç”¨æ³•: python debug_similarity.py <app1_analysis.json> <app2_analysis.json> [...]")
        print("ç¤ºä¾‹: python debug_similarity.py data/analysis_reports/Mimip_analysis.json data/analysis_reports/Zeally_analysis.json")
        sys.exit(1)
    
    app_files = sys.argv[1:]
    analyze_specific_apps(app_files)


if __name__ == "__main__":
    main() 