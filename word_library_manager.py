#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è¯åº“ç®¡ç†å·¥å…·
ç”¨äºç®¡ç†å’ŒæŸ¥è¯¢IPAåˆ†æä¸­æå–çš„å­—ç¬¦ä¸²è¯åº“
"""

import sqlite3
import json
import os
import hashlib
from datetime import datetime
from typing import Dict, List, Set, Optional
from collections import defaultdict, Counter


class WordLibraryManager:
    """è¯åº“ç®¡ç†å™¨"""
    
    def __init__(self, db_path: str = "word_library.db"):
        self.db_path = db_path
        self._init_database()
    
    def _init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # åˆ›å»ºè¯åº“è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS words (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                word TEXT UNIQUE NOT NULL,
                category TEXT NOT NULL,
                frequency INTEGER DEFAULT 1,
                first_seen TEXT NOT NULL,
                last_seen TEXT NOT NULL,
                apps_count INTEGER DEFAULT 1,
                apps_list TEXT NOT NULL,
                word_hash TEXT NOT NULL
            )
        ''')
        
        # åˆ›å»ºåº”ç”¨è®°å½•è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS apps (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                app_name TEXT NOT NULL,
                bundle_id TEXT NOT NULL,
                version TEXT NOT NULL,
                analysis_time TEXT NOT NULL,
                file_path TEXT NOT NULL,
                file_hash TEXT UNIQUE NOT NULL
            )
        ''')
        
        # åˆ›å»ºå•è¯-åº”ç”¨å…³è”è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS word_app_relations (
                word_id INTEGER,
                app_id INTEGER,
                category TEXT,
                count INTEGER DEFAULT 1,
                PRIMARY KEY (word_id, app_id),
                FOREIGN KEY (word_id) REFERENCES words (id),
                FOREIGN KEY (app_id) REFERENCES apps (id)
            )
        ''')
        
        # åˆ›å»ºç´¢å¼•
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_words_category ON words (category)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_words_apps_count ON words (apps_count)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_words_frequency ON words (frequency)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_word_hash ON words (word_hash)')
        
        conn.commit()
        conn.close()
    
    def add_analysis_data(self, analysis_file: str) -> Optional[int]:
        """ä»åˆ†ææ–‡ä»¶æ·»åŠ æ•°æ®åˆ°è¯åº“"""
        if not os.path.exists(analysis_file):
            print(f"âŒ åˆ†ææ–‡ä»¶ä¸å­˜åœ¨: {analysis_file}")
            return None
        
        try:
            with open(analysis_file, 'r', encoding='utf-8') as f:
                analysis_data = json.load(f)
        except Exception as e:
            print(f"âŒ è¯»å–åˆ†ææ–‡ä»¶å¤±è´¥: {e}")
            return None
        
        app_info = analysis_data.get('app_info', {})
        # å°è¯•ä¸¤ç§å¯èƒ½çš„å­—ç¬¦ä¸²æ•°æ®ç»“æ„
        strings_data = analysis_data.get('strings', {})
        if not strings_data:
            strings_analysis = analysis_data.get('strings_analysis', {})
            strings_data = strings_analysis.get('categories', {})
        
        return self._add_app_data(app_info, strings_data, analysis_file)
    
    def _add_app_data(self, app_info: Dict, strings_data: Dict, file_path: str) -> Optional[int]:
        """æ·»åŠ åº”ç”¨æ•°æ®"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # è®¡ç®—æ–‡ä»¶hash
        app_signature = f"{app_info.get('bundle_id', '')}{app_info.get('version', '')}"
        file_hash = hashlib.md5(app_signature.encode()).hexdigest()
        
        # æ£€æŸ¥åº”ç”¨æ˜¯å¦å·²å­˜åœ¨
        cursor.execute('SELECT id FROM apps WHERE file_hash = ?', (file_hash,))
        existing_app = cursor.fetchone()
        
        if existing_app:
            app_id = existing_app[0]
            print(f"åº”ç”¨ {app_info.get('app_name', '')} å·²å­˜åœ¨äºè¯åº“ä¸­ (ID: {app_id})")
            conn.close()
            return app_id
        
        # æ·»åŠ æ–°åº”ç”¨
        cursor.execute('''
            INSERT INTO apps (app_name, bundle_id, version, analysis_time, file_path, file_hash)
            VALUES (?, ?, ?, ?, ?, ?)
        ''', (
            app_info.get('app_name', ''),
            app_info.get('bundle_id', ''),
            app_info.get('version', ''),
            datetime.now().isoformat(),
            file_path,
            file_hash
        ))
        app_id = cursor.lastrowid
        print(f"âœ… æ–°åº”ç”¨ {app_info.get('app_name', '')} å·²æ·»åŠ åˆ°è¯åº“ (ID: {app_id})")
        
        # æ·»åŠ å­—ç¬¦ä¸²æ•°æ®
        word_count = 0
        for category, words_list in strings_data.items():
            if isinstance(words_list, list):
                for word_item in words_list:
                    # å¤„ç†ä¸åŒçš„æ•°æ®æ ¼å¼
                    if isinstance(word_item, dict) and 'content' in word_item:
                        word = word_item['content']
                    elif isinstance(word_item, str):
                        word = word_item
                    else:
                        continue
                    
                    # è¿‡æ»¤æ¡ä»¶ï¼šé•¿åº¦>=3ï¼Œä¸å…¨æ˜¯æ•°å­—/ç¬¦å·
                    if len(word.strip()) >= 3 and not word.isdigit():
                        self._add_word(cursor, word, category, app_id)
                        word_count += 1
        
        conn.commit()
        conn.close()
        
        print(f"  æ·»åŠ äº† {word_count} ä¸ªå­—ç¬¦ä¸²åˆ°è¯åº“")
        return app_id
    
    def _add_word(self, cursor, word: str, category: str, app_id: int):
        """æ·»åŠ å•è¯åˆ°è¯åº“"""
        word_hash = hashlib.md5(word.encode()).hexdigest()
        
        # æ£€æŸ¥å•è¯æ˜¯å¦å·²å­˜åœ¨
        cursor.execute('SELECT id, frequency, apps_list FROM words WHERE word_hash = ?', (word_hash,))
        existing_word = cursor.fetchone()
        
        now = datetime.now().isoformat()
        
        if existing_word:
            word_id, frequency, apps_list = existing_word
            apps_set = set(apps_list.split(',')) if apps_list else set()
            apps_set.add(str(app_id))
            
            # æ›´æ–°ç°æœ‰å•è¯
            cursor.execute('''
                UPDATE words 
                SET frequency = frequency + 1, 
                    last_seen = ?, 
                    apps_count = ?, 
                    apps_list = ?
                WHERE id = ?
            ''', (now, len(apps_set), ','.join(apps_set), word_id))
        else:
            # æ·»åŠ æ–°å•è¯
            cursor.execute('''
                INSERT INTO words (word, category, frequency, first_seen, last_seen, apps_count, apps_list, word_hash)
                VALUES (?, ?, 1, ?, ?, 1, ?, ?)
            ''', (word, category, now, now, str(app_id), word_hash))
            word_id = cursor.lastrowid
        
        # æ·»åŠ æˆ–æ›´æ–°å•è¯-åº”ç”¨å…³è”
        cursor.execute('''
            INSERT OR REPLACE INTO word_app_relations (word_id, app_id, category, count)
            VALUES (?, ?, ?, COALESCE((SELECT count + 1 FROM word_app_relations WHERE word_id = ? AND app_id = ?), 1))
        ''', (word_id, app_id, category, word_id, app_id))
    
    def get_common_words(self, min_apps: int = 2, category: str = None, limit: int = 100) -> List[Dict]:
        """è·å–å…±åŒå•è¯"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        query = '''
            SELECT w.word, w.category, w.apps_count, w.frequency, w.apps_list
            FROM words w
            WHERE w.apps_count >= ?
        '''
        params = [min_apps]
        
        if category:
            query += ' AND w.category = ?'
            params.append(category)
        
        query += ' ORDER BY w.apps_count DESC, w.frequency DESC LIMIT ?'
        params.append(limit)
        
        cursor.execute(query, params)
        
        results = []
        for row in cursor.fetchall():
            word, cat, apps_count, frequency, apps_list = row
            results.append({
                'word': word,
                'category': cat,
                'apps_count': apps_count,
                'frequency': frequency,
                'apps_list': apps_list.split(',') if apps_list else []
            })
        
        conn.close()
        return results
    
    def search_words(self, pattern: str, category: str = None, limit: int = 50) -> List[Dict]:
        """æœç´¢å•è¯"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        query = '''
            SELECT w.word, w.category, w.apps_count, w.frequency
            FROM words w
            WHERE w.word LIKE ?
        '''
        params = [f'%{pattern}%']
        
        if category:
            query += ' AND w.category = ?'
            params.append(category)
        
        query += ' ORDER BY w.frequency DESC LIMIT ?'
        params.append(limit)
        
        cursor.execute(query, params)
        
        results = []
        for row in cursor.fetchall():
            word, cat, apps_count, frequency = row
            results.append({
                'word': word,
                'category': cat,
                'apps_count': apps_count,
                'frequency': frequency
            })
        
        conn.close()
        return results
    
    def get_statistics(self) -> Dict:
        """è·å–è¯åº“ç»Ÿè®¡ä¿¡æ¯"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # åŸºæœ¬ç»Ÿè®¡
        cursor.execute('SELECT COUNT(*) FROM apps')
        total_apps = cursor.fetchone()[0]
        
        cursor.execute('SELECT COUNT(*) FROM words')
        total_words = cursor.fetchone()[0]
        
        # æŒ‰åˆ†ç±»ç»Ÿè®¡
        cursor.execute('SELECT category, COUNT(*) FROM words GROUP BY category ORDER BY COUNT(*) DESC')
        category_stats = dict(cursor.fetchall())
        
        # å…±åŒå•è¯ç»Ÿè®¡
        cursor.execute('SELECT apps_count, COUNT(*) FROM words GROUP BY apps_count ORDER BY apps_count DESC')
        common_words_stats = dict(cursor.fetchall())
        
        # æœ€é¢‘ç¹çš„å•è¯
        cursor.execute('SELECT word, frequency, apps_count FROM words ORDER BY frequency DESC LIMIT 10')
        top_frequent_words = [{'word': row[0], 'frequency': row[1], 'apps_count': row[2]} for row in cursor.fetchall()]
        
        # åº”ç”¨ä¿¡æ¯
        cursor.execute('SELECT app_name, bundle_id, analysis_time FROM apps ORDER BY analysis_time DESC')
        apps_info = [{'name': row[0], 'bundle_id': row[1], 'time': row[2]} for row in cursor.fetchall()]
        
        conn.close()
        
        return {
            'total_apps': total_apps,
            'total_words': total_words,
            'category_stats': category_stats,
            'common_words_stats': common_words_stats,
            'top_frequent_words': top_frequent_words,
            'apps_info': apps_info
        }
    
    def export_common_words(self, output_file: str, min_apps: int = 2):
        """å¯¼å‡ºå…±åŒå•è¯åˆ°CSVæ–‡ä»¶"""
        common_words = self.get_common_words(min_apps=min_apps, limit=1000)
        
        import csv
        with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:
            fieldnames = ['word', 'category', 'apps_count', 'frequency', 'apps_list']
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            
            writer.writeheader()
            for word_info in common_words:
                writer.writerow({
                    'word': word_info['word'],
                    'category': word_info['category'],
                    'apps_count': word_info['apps_count'],
                    'frequency': word_info['frequency'],
                    'apps_list': ','.join(word_info['apps_list'])
                })
        
        print(f"âœ… å…±åŒå•è¯å·²å¯¼å‡ºåˆ°: {output_file}")
    
    def generate_word_cloud_data(self, min_apps: int = 2, category: str = None) -> Dict:
        """ç”Ÿæˆè¯äº‘æ•°æ®"""
        common_words = self.get_common_words(min_apps=min_apps, category=category, limit=200)
        
        word_cloud_data = {}
        for word_info in common_words:
            # è¯äº‘æƒé‡ = å‡ºç°é¢‘ç‡ Ã— åº”ç”¨æ•°é‡
            weight = word_info['frequency'] * word_info['apps_count']
            word_cloud_data[word_info['word']] = weight
        
        return word_cloud_data
    
    def analyze_app_similarity_by_words(self) -> Dict:
        """åŸºäºè¯åº“åˆ†æåº”ç”¨ç›¸ä¼¼æ€§"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # è·å–æ‰€æœ‰åº”ç”¨
        cursor.execute('SELECT id, app_name FROM apps')
        apps = dict(cursor.fetchall())
        
        app_similarity = {}
        app_ids = list(apps.keys())
        
        for i, app1_id in enumerate(app_ids):
            for app2_id in app_ids[i+1:]:
                # è·å–ä¸¤ä¸ªåº”ç”¨çš„å…±åŒå•è¯
                cursor.execute('''
                    SELECT COUNT(*) as common_words
                    FROM word_app_relations war1
                    JOIN word_app_relations war2 ON war1.word_id = war2.word_id
                    WHERE war1.app_id = ? AND war2.app_id = ?
                ''', (app1_id, app2_id))
                
                common_words_count = cursor.fetchone()[0]
                
                # è·å–å„è‡ªçš„æ€»å•è¯æ•°
                cursor.execute('SELECT COUNT(*) FROM word_app_relations WHERE app_id = ?', (app1_id,))
                app1_words_count = cursor.fetchone()[0]
                
                cursor.execute('SELECT COUNT(*) FROM word_app_relations WHERE app_id = ?', (app2_id,))
                app2_words_count = cursor.fetchone()[0]
                
                # è®¡ç®—Jaccardç›¸ä¼¼åº¦
                total_unique_words = app1_words_count + app2_words_count - common_words_count
                similarity = common_words_count / total_unique_words if total_unique_words > 0 else 0
                
                app1_name = apps[app1_id]
                app2_name = apps[app2_id]
                app_similarity[f"{app1_name}_vs_{app2_name}"] = {
                    'similarity': round(similarity * 100, 2),
                    'common_words': common_words_count,
                    'app1_words': app1_words_count,
                    'app2_words': app2_words_count
                }
        
        conn.close()
        return app_similarity


def main():
    """ä¸»å‡½æ•° - å‘½ä»¤è¡Œå·¥å…·"""
    import argparse
    
    parser = argparse.ArgumentParser(description='è¯åº“ç®¡ç†å·¥å…·')
    parser.add_argument('--add', help='æ·»åŠ åˆ†ææ–‡ä»¶åˆ°è¯åº“')
    parser.add_argument('--add-dir', help='æ·»åŠ ç›®å½•ä¸­çš„æ‰€æœ‰åˆ†ææ–‡ä»¶åˆ°è¯åº“')
    parser.add_argument('--stats', action='store_true', help='æ˜¾ç¤ºè¯åº“ç»Ÿè®¡ä¿¡æ¯')
    parser.add_argument('--common', type=int, default=2, help='æ˜¾ç¤ºå‡ºç°åœ¨Nä¸ªä»¥ä¸Šåº”ç”¨ä¸­çš„å…±åŒå•è¯')
    parser.add_argument('--search', help='æœç´¢åŒ…å«æŒ‡å®šæ¨¡å¼çš„å•è¯')
    parser.add_argument('--category', help='æŒ‰åˆ†ç±»è¿‡æ»¤')
    parser.add_argument('--export', help='å¯¼å‡ºå…±åŒå•è¯åˆ°CSVæ–‡ä»¶')
    parser.add_argument('--similarity', action='store_true', help='åˆ†æåº”ç”¨ç›¸ä¼¼æ€§')
    
    args = parser.parse_args()
    
    wlm = WordLibraryManager()
    
    if args.add:
        wlm.add_analysis_data(args.add)
    
    elif args.add_dir:
        if os.path.exists(args.add_dir):
            for filename in os.listdir(args.add_dir):
                if filename.endswith('_analysis.json'):
                    filepath = os.path.join(args.add_dir, filename)
                    wlm.add_analysis_data(filepath)
        else:
            print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {args.add_dir}")
    
    elif args.stats:
        stats = wlm.get_statistics()
        print(f"ğŸ“Š è¯åº“ç»Ÿè®¡ä¿¡æ¯:")
        print(f"   æ€»åº”ç”¨æ•°: {stats['total_apps']}")
        print(f"   æ€»å•è¯æ•°: {stats['total_words']}")
        print(f"\nğŸ“ åˆ†ç±»ç»Ÿè®¡:")
        for category, count in stats['category_stats'].items():
            print(f"   {category}: {count}")
        print(f"\nğŸ”„ å…±åŒå•è¯ç»Ÿè®¡:")
        for apps_count, words_count in stats['common_words_stats'].items():
            print(f"   å‡ºç°åœ¨{apps_count}ä¸ªåº”ç”¨ä¸­: {words_count}ä¸ªå•è¯")
    
    elif args.common:
        common_words = wlm.get_common_words(min_apps=args.common, category=args.category)
        print(f"ğŸ“ å‡ºç°åœ¨{args.common}ä¸ªä»¥ä¸Šåº”ç”¨ä¸­çš„å…±åŒå•è¯ (å…±{len(common_words)}ä¸ª):")
        for word_info in common_words[:20]:  # æ˜¾ç¤ºå‰20ä¸ª
            apps_str = ', '.join(word_info['apps_list'])
            print(f"   {word_info['word']} ({word_info['category']}) - é¢‘ç‡:{word_info['frequency']}, åº”ç”¨:{apps_str}")
        if len(common_words) > 20:
            print(f"   ... è¿˜æœ‰{len(common_words) - 20}ä¸ªå•è¯")
    
    elif args.search:
        results = wlm.search_words(args.search, category=args.category)
        print(f"ğŸ” æœç´¢ç»“æœ (æ¨¡å¼: '{args.search}', å…±{len(results)}ä¸ª):")
        for word_info in results:
            print(f"   {word_info['word']} ({word_info['category']}) - é¢‘ç‡:{word_info['frequency']}, åº”ç”¨æ•°:{word_info['apps_count']}")
    
    elif args.export:
        wlm.export_common_words(args.export, min_apps=args.common)
    
    elif args.similarity:
        similarity = wlm.analyze_app_similarity_by_words()
        print("ğŸ” åŸºäºè¯åº“çš„åº”ç”¨ç›¸ä¼¼æ€§åˆ†æ:")
        for pair, data in sorted(similarity.items(), key=lambda x: x[1]['similarity'], reverse=True):
            print(f"   {pair}: {data['similarity']}% (å…±åŒå•è¯:{data['common_words']})")
    
    else:
        parser.print_help()


if __name__ == '__main__':
    main() 