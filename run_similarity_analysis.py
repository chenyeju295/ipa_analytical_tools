#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
IPAç›¸ä¼¼æ€§åˆ†æè„šæœ¬
"""

import json
import os
from collections import defaultdict
from datetime import datetime

def load_analysis_files(analysis_dir):
    """åŠ è½½åˆ†ææ–‡ä»¶"""
    analyses = {}
    for filename in os.listdir(analysis_dir):
        if filename.endswith('_analysis.json') and filename != 'similarity_analysis.json':
            app_name = filename.replace('_analysis.json', '')
            filepath = os.path.join(analysis_dir, filename)
            try:
                with open(filepath, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    analyses[app_name] = data
                    print(f'âœ… åŠ è½½åˆ†ææ–‡ä»¶: {app_name}')
            except Exception as e:
                print(f'âŒ åŠ è½½æ–‡ä»¶å¤±è´¥ {filename}: {e}')
    return analyses

def extract_all_strings(strings_data):
    """æå–æ‰€æœ‰å­—ç¬¦ä¸²"""
    all_strings = set()
    for category, strings_list in strings_data.items():
        if isinstance(strings_list, list):
            for item in strings_list:
                if isinstance(item, dict) and 'content' in item:
                    all_strings.add(item['content'])
                elif isinstance(item, str):
                    all_strings.add(item)
    return all_strings

def extract_resource_names(resources_data):
    """æå–èµ„æºæ–‡ä»¶å"""
    resource_names = set()
    files_list = resources_data.get('files', [])
    for file_info in files_list:
        if isinstance(file_info, dict) and 'name' in file_info:
            filename = os.path.basename(file_info['name'])
            resource_names.add(filename)
    return resource_names

def analyze_common_strings(analyses):
    """åˆ†æå…±åŒå­—ç¬¦ä¸²"""
    string_frequency = defaultdict(list)
    
    for app_name, analysis in analyses.items():
        strings = extract_all_strings(analysis.get('strings', {}))
        for string in strings:
            string_frequency[string].append(app_name)
    
    common_strings = {}
    for string, apps in string_frequency.items():
        freq = len(apps)
        if freq > 1:
            if freq not in common_strings:
                common_strings[freq] = []
            common_strings[freq].append({
                'string': string,
                'apps': apps,
                'frequency': freq
            })
    
    for freq in common_strings:
        common_strings[freq].sort(key=lambda x: len(x['string']))
    
    return common_strings

def analyze_common_resources(analyses):
    """åˆ†æå…±åŒèµ„æº"""
    resource_frequency = defaultdict(list)
    
    for app_name, analysis in analyses.items():
        resources = extract_resource_names(analysis.get('resources', {}))
        for resource in resources:
            resource_frequency[resource].append(app_name)
    
    common_resources = {}
    for resource, apps in resource_frequency.items():
        freq = len(apps)
        if freq > 1:
            if freq not in common_resources:
                common_resources[freq] = []
            common_resources[freq].append({
                'resource': resource,
                'apps': apps,
                'frequency': freq
            })
    
    for freq in common_resources:
        common_resources[freq].sort(key=lambda x: x['resource'])
    
    return common_resources

def calculate_pairwise_similarity(app1_data, app2_data, app1_name, app2_name):
    """è®¡ç®—æˆå¯¹ç›¸ä¼¼æ€§"""
    # å­—ç¬¦ä¸²ç›¸ä¼¼æ€§
    strings1 = extract_all_strings(app1_data.get('strings', {}))
    strings2 = extract_all_strings(app2_data.get('strings', {}))
    
    common_strings = strings1.intersection(strings2)
    total_unique_strings = strings1.union(strings2)
    
    string_similarity = len(common_strings) / len(total_unique_strings) if total_unique_strings else 0
    
    # èµ„æºç›¸ä¼¼æ€§
    resources1 = extract_resource_names(app1_data.get('resources', {}))
    resources2 = extract_resource_names(app2_data.get('resources', {}))
    
    common_resources = resources1.intersection(resources2)
    total_unique_resources = resources1.union(resources2)
    
    resource_similarity = len(common_resources) / len(total_unique_resources) if total_unique_resources else 0
    
    # Bundle IDç›¸ä¼¼æ€§
    bundle1 = app1_data.get('app_info', {}).get('bundle_id', '')
    bundle2 = app2_data.get('app_info', {}).get('bundle_id', '')
    
    if bundle1 and bundle2:
        parts1 = bundle1.split('.')
        parts2 = bundle2.split('.')
        
        common_prefix_length = 0
        for p1, p2 in zip(parts1, parts2):
            if p1 == p2:
                common_prefix_length += 1
            else:
                break
        
        max_parts = max(len(parts1), len(parts2))
        bundle_similarity = common_prefix_length / max_parts if max_parts > 0 else 0.0
    else:
        bundle_similarity = 0.0
    
    # ç»¼åˆç›¸ä¼¼æ€§å¾—åˆ†
    overall_similarity = (string_similarity * 0.4 + resource_similarity * 0.3 + bundle_similarity * 0.3)
    
    return {
        'string_similarity': round(string_similarity * 100, 2),
        'resource_similarity': round(resource_similarity * 100, 2),
        'bundle_similarity': round(bundle_similarity * 100, 2),
        'overall_similarity': round(overall_similarity * 100, 2),
        'common_strings_count': len(common_strings),
        'common_resources_count': len(common_resources)
    }

def main():
    """ä¸»å‡½æ•°"""
    print('ğŸ” IPAç›¸ä¼¼æ€§åˆ†æå¼€å§‹...')
    analyses = load_analysis_files('analysis_reports')

    if analyses:
        print(f'\nğŸ“Š å·²åŠ è½½ {len(analyses)} ä¸ªåº”ç”¨çš„åˆ†ææ•°æ®')
        
        # æˆå¯¹ç›¸ä¼¼æ€§åˆ†æ
        pairwise_similarity = {}
        app_names = list(analyses.keys())
        
        for i, app1 in enumerate(app_names):
            for j, app2 in enumerate(app_names[i+1:], i+1):
                similarity = calculate_pairwise_similarity(
                    analyses[app1], analyses[app2], app1, app2
                )
                pairwise_similarity[f'{app1}_vs_{app2}'] = similarity
        
        # å…±åŒå­—ç¬¦ä¸²åˆ†æ
        common_strings = analyze_common_strings(analyses)
        
        # å…±åŒèµ„æºåˆ†æ
        common_resources = analyze_common_resources(analyses)
        
        # æ˜¾ç¤ºç»“æœ
        print('\nğŸ” åº”ç”¨é—´ç›¸ä¼¼æ€§å¯¹æ¯”:')
        print('=' * 80)
        for pair_name, similarity in sorted(pairwise_similarity.items(), 
                                           key=lambda x: x[1]['overall_similarity'], 
                                           reverse=True):
            apps = pair_name.replace('_vs_', ' vs ')
            print(f'{apps:30} | æ•´ä½“: {similarity["overall_similarity"]:5.1f}% | '
                  f'å­—ç¬¦ä¸²: {similarity["string_similarity"]:5.1f}% | '
                  f'èµ„æº: {similarity["resource_similarity"]:5.1f}% | '
                  f'Bundle: {similarity["bundle_similarity"]:5.1f}%')
        
        # æ˜¾ç¤ºå…±åŒå­—ç¬¦ä¸²
        total_common_strings = sum(len(strings) for strings in common_strings.values())
        print(f'\nğŸ”¤ å…±åŒå­—ç¬¦ä¸²åˆ†æ (æ€»è®¡ {total_common_strings} ä¸ª):')
        print('=' * 50)
        
        for freq in sorted(common_strings.keys(), reverse=True):
            strings_list = common_strings[freq]
            print(f'\nåœ¨ {freq} ä¸ªåº”ç”¨ä¸­å‡ºç°çš„å­—ç¬¦ä¸² ({len(strings_list)} ä¸ª):')
            for string_info in strings_list[:5]:  # æ˜¾ç¤ºå‰5ä¸ª
                apps_str = ', '.join(string_info['apps'])
                string_preview = string_info['string'][:40] + '...' if len(string_info['string']) > 40 else string_info['string']
                print(f'  - {string_preview} (åº”ç”¨: {apps_str})')
            if len(strings_list) > 5:
                print(f'  ... è¿˜æœ‰ {len(strings_list) - 5} ä¸ªå­—ç¬¦ä¸²')
        
        # æ˜¾ç¤ºå…±åŒèµ„æº
        total_common_resources = sum(len(resources) for resources in common_resources.values())
        print(f'\nğŸ“ å…±åŒèµ„æºåˆ†æ (æ€»è®¡ {total_common_resources} ä¸ª):')
        print('=' * 50)
        
        for freq in sorted(common_resources.keys(), reverse=True):
            resources_list = common_resources[freq]
            print(f'\nåœ¨ {freq} ä¸ªåº”ç”¨ä¸­å‡ºç°çš„èµ„æº ({len(resources_list)} ä¸ª):')
            for resource_info in resources_list[:10]:  # æ˜¾ç¤ºå‰10ä¸ª
                apps_str = ', '.join(resource_info['apps'])
                print(f'  - {resource_info["resource"]} (åº”ç”¨: {apps_str})')
            if len(resources_list) > 10:
                print(f'  ... è¿˜æœ‰ {len(resources_list) - 10} ä¸ªèµ„æº')
        
        # Bundle IDæ¨¡å¼åˆ†æ
        print(f'\nğŸ·ï¸ Bundle IDæ¨¡å¼åˆ†æ:')
        print('=' * 50)
        bundle_ids = []
        for app in app_names:
            app_info = analyses[app].get('app_info', {})
            bundle_id = app_info.get('bundle_id', 'N/A')
            bundle_ids.append(bundle_id)
        
        valid_bundle_ids = [bid for bid in bundle_ids if bid != 'N/A']
        if valid_bundle_ids:
            common_prefix = os.path.commonprefix(valid_bundle_ids)
            print(f'å…¬å…±å‰ç¼€: {common_prefix} (é•¿åº¦: {len(common_prefix)})')
        else:
            common_prefix = ''
            print('æœªæ‰¾åˆ°æœ‰æ•ˆçš„Bundle ID')
        
        for app_name, bundle_id in zip(app_names, bundle_ids):
            print(f'  {app_name}: {bundle_id}')
        
        # ä¿å­˜è¯¦ç»†ç»“æœ
        similarity_results = {
            'pairwise_similarity': pairwise_similarity,
            'common_strings': common_strings,
            'common_resources': common_resources,
            'analysis_timestamp': datetime.now().isoformat(),
            'total_apps': len(analyses)
        }
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        with open('analysis_reports/similarity_analysis.json', 'w', encoding='utf-8') as f:
            json.dump(similarity_results, f, ensure_ascii=False, indent=2)
        
        print('\nâœ… ç›¸ä¼¼æ€§åˆ†æå®Œæˆï¼è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ° analysis_reports/similarity_analysis.json')
        
        # æ˜¾ç¤ºæ€»ç»“
        highest_similarity = max(pairwise_similarity.items(), key=lambda x: x[1]['overall_similarity'])
        print(f'\nğŸ¯ å…³é”®å‘ç°:')
        print(f'   - æœ€ç›¸ä¼¼çš„åº”ç”¨å¯¹: {highest_similarity[0]} (ç›¸ä¼¼åº¦: {highest_similarity[1]["overall_similarity"]}%)')
        print(f'   - å…±åŒå­—ç¬¦ä¸²æ€»æ•°: {total_common_strings} ä¸ª')
        print(f'   - å…±åŒèµ„æºæ€»æ•°: {total_common_resources} ä¸ª')
        print(f'   - Bundle IDå…¬å…±å‰ç¼€é•¿åº¦: {len(common_prefix)} ä¸ªå­—ç¬¦')
        
    else:
        print('âŒ æœªæ‰¾åˆ°å¯åˆ†æçš„æ–‡ä»¶')

if __name__ == '__main__':
    main() 